<html>
<head>
<title>IPPL  Tutorial 4: Advanced Topics</title>
<link rel=StyleSheet href="http://amas.web.psi.ch/css/basic-style.css" type="text/css">
</head>
<body bgcolor="#FFFFFF">
<h1>IPPL&nbsp; Tutorial 4: Advanced Topics </h1>
<p><b>Contents:</b>
<br>&nbsp;&nbsp;&nbsp;&nbsp;<a href="#intro">Introduction</a>

<p><b>Contents:</b>
<br>&nbsp;&nbsp;&nbsp;&nbsp;<a href="#intro">Introduction</a>
<br>&nbsp;&nbsp;&nbsp;&nbsp;<a href="#blockevaluate">Block And Evaluate</a>
<br>&nbsp;&nbsp;&nbsp;&nbsp;<a href="#pointwise">Pointwise Functions</a>
<br>&nbsp;&nbsp;&nbsp;&nbsp;<a href="#tiny">Small Vectors and Tensors</a>
<br>&nbsp;&nbsp;&nbsp;&nbsp;<a href="#layout">Taking Layout Into Account</a>

<!---------------------------------------------------------------------->
<a name="intro"><h2>Introduction</h2></a>

<p>One of IPPL&nbsp;'s most attractive features is its high
performance on both single-processor and shared-memory multiprocessor
machines.  As future releases of the library will also support
distributed-memory multicomputers and networks of workstations,
IPPL&nbsp;'s authors have had to think very carefully about how to
obtain the best possible performance across a wide range of
applications on different architectures.

<p>The heart of the problem IPPL&nbsp;'s authors face is that while
data-parallel programming is a natural way to express many scientific
and numerical algorithms, straightforward implementations of it do
exactly the wrong thing on modern RISC architectures, whose
performance depends critically on the re-use of data loaded into
cache.  If a program evaluates <tt>A+B+C</tt> for three arrays
<tt>A</tt>, <tt>B</tt>, and <tt>C</tt> by adding <tt>A</tt> to
<tt>B</tt>, then adding <tt>C</tt> to that calculation's result,
performance suffers both because of the overhead of executing two
loops instead of one, but also (and more importantly) because every
value in the temporary array that stores the result of <tt>A+B</tt>
has to be accessed twice: once to write it, and once to read it back
in.  As soon as this array is too large to fit into cache, the
program's performance will drop dramatically.

<p>The first section of this tutorial explains what IPPL&nbsp; does
to solve this problem.  Subsequent sections discuss other advanced
aspects of IPPL&nbsp;, such as how to build pointwise functions, or
reduction functions that will execute efficiently regardless of how
arrays are laid out in memory.

<!---------------------------------------------------------------------->
<a name="blockevaluate"><h2>Block And Evaluate</h2></a>

<p>IPPL&nbsp; tries to resolve the tension between how programmers
want to express their ideas, and what runs most efficiently on modern
architectures, by delaying the evaluation of expressions until enough
is known about their context to ensure that they can be evaluated
efficiently.  It does this by blocking calculations into units called
iterates, and putting those iterates into a queue of work that is
still to be done.  Each iterate is a portion of a computation, over a
portion of a domain.  IPPL&nbsp; tracks data dependencies between
iterates dynamically to ensure that out-of-order computation cannot
occur.

<p>Depending on the switches specified during configuration when the
library is installed, and the version of the IPPL&nbsp; library
that a program is linked against, IPPL&nbsp; will run in one of
four different modes.  In the first mode, the work queue doesn't
actually exist.  Instead, the single thread of execution in the
program evaluates iterates as soon as they are "enqueued", i.e. work
is done immediately.  The result is that all of the calculations in a
statement are completed by the time execution reaches the semi-colon
at the end of that statement.

<p>In its second mode, IPPL&nbsp; maintains the work queue, but all
work is done by a single thread.  The queue is used because the
explicit parceling up of work into iterates gives IPPL&nbsp; an
opportunity to re-order or combine those iterates.  While the overhead
of maintaining and inspecting the work queue can slow down operations
on small arrays, it makes operations on large arrays much faster.

<p>For example, consider the four function calls that perform
red/black relaxation in <a href="tut-2.html#redblack">the second
tutorial</a>.  In order to get the highest possible performance out of
the cache, all four of these expressions should be evaluated on a
given cache block before any of the expressions are evaluated for the
next cache block.  Managing this by hand is a nightmare, both because
cache size varies from machine to machine (even when those machines
come from the same manufacturer), and because very slight changes in
the dimensions of arrays can tip them in or out of cache.
IPPL&nbsp;'s array classes and overloaded operators do part of the
job by creating appropriately-sized iterates; its work queue does the
rest of the job by deciding how best to evaluate them.  The net result
is higher performance for less programmer effort.

<p>IPPL&nbsp;'s third and fourth modes of operation are
multi-threaded.  Each thread in a pool takes iterates from the work
queue when and as they become available.  Iterates are evaluated
independently; the difference between the two modes is that one is
synchronous, and blocks after evaluating each data-parallel statement,
while the other is asynchronous, i.e. permits out-of-order execution.
The table <a href="#operation-mode-table">below</a> summarizes these
four modes, along with the <a
href="install.html#configure-arguments">configuration arguments</a>
used to produce each.

<a name="operation-mode-table">
<p><center><table border=2>

<tr>	<td valign=top>
		<table>
		<tr>	<td><b>1. Synchronous Serial</b>		</tr>
		<tr>	<td>Conventional sequential execution		</tr>
		<tr>	<td><tt>--serial</tt>				</tr>
		</table>
	<td valign=top>
		<table>
		<tr>	<td><b>2. Asynchronous Serial</b>		</tr>
		<tr>	<td>Serial work queue				</tr>
		<tr>	<td><tt>--parallel --sched serialAsync</tt>	</tr>
		</table>
	</tr>

<tr>	<td valign=top>
		<table>
		<tr>	<td><b>3. Synchronous Parallel</b>		</tr>
		<tr>	<td>Multithreaded, blocking after each
			<br>data-parallel statement			</tr>
		<tr>	<td><tt>--parallel --sched sync</tt>		</tr>
		</table>
	<td valign=top>
		<table>
		<tr>	<td><b>4. Asynchronous Parallel</b>		</tr>
		<tr>	<td>Multithreaded, out-of-order execution
			<br>&nbsp;					</tr>
		<tr>	<td><tt>--parallel --sched async</tt>		</tr>
		</table>
	</tr>

</table></center>
</a>

<p>A very important function in IPPL&nbsp;'s work allocation system
is <tt>Ippl::blockAndEvaluate()</tt>.  It is one of only two
functions that expose the library's internal parallelism and cache
optimizations to users.  While IPPL&nbsp; automatically calls it at
the right times in most cases, there are a few situations in which
programmers should call it explicitly.

<p>If evaluation has been deferred, the statements being evaluated are
not guaranteed to have completed until <tt>blockAndEvaluate()</tt> is
called.  IPPL&nbsp; does this by itself inside of
<tt>operator&lt;&lt;</tt>, reductions, and so on, but there is a place
where the performance overhead of doing that check would be so high as
to be unacceptable: indexing with integers.  If
<tt>blockAndEvaluate()</tt> was called inside every use of
<tt>operator()</tt>, it would be impossible to write serial loops
efficiently.

<p>This means that when a program is running in modes 2-4 (i.e. using
either parallelism or potentially asynchronous execution), it must
call <tt>blockAndEvaluate()</tt> before subscripting arrays with
integers.  Failure to do so can lead to race conditions, and other
hard-to-find errors.

<p>Typical uses of <tt>blockAndEvaluate()</tt> look like:

<blockquote><pre>
Array&lt;2&gt; A(N, N);
A = 0;
Ippl::blockAndEvaluate();
A(N/2, N/2) = 1;
</pre></blockquote>

<p>or:

<blockquote><pre>
Loc&lt;2&gt; center(N/2, N/2);
Ippl::blockAndEvaluate();
A(center) = 1;
</pre></blockquote>

<p>Without the calls, the code might not parallelize correctly.  If, however, code like the
following is used instead:

<blockquote><pre>
Interval&lt;2&gt; center(Interval&lt;1&gt;(N/2, N/2), Interval&lt;1&gt;(N/2, N/2));
A(center) = 1;
</pre></blockquote>

<p>then correct execution is guaranteed, because this assignment will
be handled using all of IPPL&nbsp;'s parallel machinery.  Of
course, the safe version is somewhat slower, and should not be used
inside a time-critical loop, since it would implicitly be doing
locking and unlocking on every call.

<p>It can be very tedious to place <tt>blockAndEvaluate()</tt> calls
in code that mixes scalar and data-parallel statements. It is easier
and less error-prone to simply turn off asynchronous operation
temporarily. This is accomplished by calling
<tt>Ippl::blockingExpressions(true)</tt> at the beginning of such a
block and then calling <tt>Ippl::blockingExpressions(false)</tt> at
the end.

<!---------------------------------------------------------------------->
<a name="pointwise"><h2>Pointwise Functions</h2></a>

<p>One of the major goals of the Developer Release&nbsp;1.0 of
IPPL&nbsp; is to support stencil-based computation on large arrays.
Since the simplest possible stencil consists of just a single point,
and since the other major goal of IPPL&nbsp;'s first release is
high performance, the library provides a way for users to write their
own pointwise functions on arrays.

<p>The program below (included in the release as
<tt>examples/UserFunction/CosTimes</tt>) shows how to do this by
instantiating a IPPL&nbsp; class called
<tt>UserFunction&lt;&gt;</tt>, and providing a method in that class
called <tt>apply()</tt>.

<blockquote><pre>
01  #include &lt;Ippl/Arrays.h&gt;
02
03  #include &lt;math.h&gt;
04  
05 // <em>The class representing the pointwise operation</em>
06  class CosTimes : public UserFunction&lt;CosTimes&gt;
07  {
08    public:
09      CosTimes(
10          double x
11      )
12      : x_(x)
13      {}
14  
15     double apply(
16          double y
17      ) const {
18          return cos(x_ * y);
19      }
20  
21    private:
22      double x_;
23  };
24  
25 // <em>Main body of program.</em>
26  int main(
27      int                 argc,
28      char *              argv[]
29  ){
30      // <em>Initialize Ippl.</em>
31      Ippl::initialize(argc, argv);
32  
33      int N=5;
34      Array&lt;2&gt; x(N,N);
35 
36      // <em>Fill the array with some data.</em>
37      for (int i=0; i&lt;N; ++i)
38          for (int j=0; j&lt;N; ++j)
39              x(i,j) = i+0.1*j;
40  
41      // <em>Build an object that takes cosine of 2*pi*x</em>
42      CosTimes cos2pi(4.0 * asin(1.0));
43  
44      // <em>An array to test the output.</em>
45     Array&lt;2&gt; y(N,N);
46  
47      // <em>This should be zero everywhere.</em>
48      // <em>These are two ways to phrase the same thing.</em>
49      y = cos2pi(x) - cos(2*M_PI*x);
50  
51      // <em>Make sure the difference is zero.</em>
52      double diff = sum(y*y);
53      cout &lt;&lt; diff &lt;&lt; endl;
54  
55     // <em>Clean up and report success.</em>
56      Ippl::finalize();
57      return 0;
58  }
</pre></blockquote>

<p>Note how the name of the class being created, <tt>CosTimes</tt>, is
passed as a template argument to <tt>UserFunction&lt;&gt;</tt>, the
class from which <tt>CosTimes</tt> is being derived.  Despite its
rather odd appearance, this is both legal and useful.  The reason is
that the methods of the parent class <tt>UserFunction&lt;&gt;</tt>
need to call the <tt>apply()</tt> method defined in the derived class.
Since we don't want to make <tt>apply()</tt> a virtual method (the
performance penalty would be too high), the key portion of
<tt>UserFunction&lt;&gt;</tt> is defined as follows:

<blockquote><pre>
template&lt;class T&gt;
class UserFunction : ...
{
  public :
    // <em>constructors, destructors, etc.</em>

    // <em>apply the function</em>
    void doTheWork()
    {
        for (double e = <em>each array element in turn</em>)
        {
            e = T::apply(e);
        }
    }
};
</pre></blockquote>

<p>Thus, when <tt>CosTimes</tt> is derived from
<tt>UserFunction&lt;CosTimes&gt;</tt>, the call to <tt>T::apply()</tt>
is expanded to create a called to <tt>CosTimes::apply()</tt>, as
desired.  At the same time, <tt>CosTimes</tt> inherits all of the
machinery to loop over all array elements efficiently (which is
considerably more complex than what has been shown here).

<!---------------------------------------------------------------------->
<a name="tiny"><h2>Small Vectors and Tensors</h2></a>

<p>IPPL&nbsp; includes two "tiny" classes that are optimized to
represent small vectors and tensors.  Not surprisingly, these are
called <tt>Vector&lt;&gt;</tt> and <tt>Tensor&lt;&gt;</tt>; their
declarations are:

<blockquote><pre>
template&lt;int Size, class T = double, class EngineTag = Full&gt;
struct Vector;

template<int Size1, int Size2, class T = double, class EngineTag = Full>
struct Tensor;
</pre></blockquote>

<p>The size parameters specify the fixed size(s) of the objects, and
are used as follows:

<blockquote><pre>
Vector&lt;3&gt; v;         // <em>3-component vector of doubles.</em>

Vector&lt;2, int&gt; vi;   // <em>2-component vector of ints.</em>

Tensor&lt;2, 2, int&gt; t; // <em>2&times;2 tensor of ints.</em>
</blockquote></pre>

<p>Note that these classes use engine abstractions, just like their
grown-up <tt>Array&lt;&gt;</tt> counterpart.  However, the only engine
class available for <tt>Vector&lt;&gt;</tt> and
<tt>Tensor&lt;&gt;</tt> in this release is <tt>Full</tt>, which
signals that all elements of the vector or tensor are stored. Future
releases of IPPL&nbsp; will include engines specialized to store
such things as diagonal tensors.

<p>The code below (included in the release as <tt>examples/Tiny</tt>)
is a short example of how these two classes can be used:

<blockquote><pre>
01 #include "Ippl/Arrays.h"
02
03 int main(
04      int                 argc,           // <em>argument count</em>
05      char *              argv[]          // <em>argument list</em>
06 ){
07  // <em>Initialize Ippl.</em>
08  Ippl::initialize(argc, argv);
09
10  // <em>Make an array of 100 3D ray vectors.</em>
11  Loc&lt;1&gt; patchSize(25);
12  GridLayout&lt;1&gt; layout(Interval&lt;1&gt;(100), patchSize);
13  Array&lt;1, Vector&lt;3&gt;, UniformMultiPatch&lt;Brick&gt; &gt; rays(layout);
14  
15  // <em>Set the third component of all of the vectors to zero.</em>
16  rays.comp(2) = 0.0;
17  
18  // <em>Starting some scalar code, must block.</em>
19  Ippl::blockAndEvaluate();
20  
21  // <em>Fill the vectors with a random value for the first component.</em>
22  for (int i = 0; i&lt;100; i++)
23  {
24    rays(i)(0) = rand() / static_cast&lt;double&gt;(RAND_MAX);
25  }
26
27  // <em>Define a unit vector pointing in the y direction.</em>
28  Vector&lt;3&gt; n(0.0, 1.0, 0.0);
29    
30  // <em>Set the second component so that the length is one.</em>
31  rays.comp(1) = sqrt(1.0 - rays.comp(0) * rays.comp(0));
32
33  // <em>Reflect the rays off of a plane perpendicular to the y axis.  </em>
34  rays += -2.0 * dot(rays, n) * n;
35  
36  // <em>Output the rays.</em>
37  cout &lt;&lt; rays &lt;&lt; endl;
38  
39  // <em>Clean up and leave.</em>
40  Ippl::finalize();
41  return 0;
42 }
</pre></blockquote>

<p>As line&nbsp;13 of this code shows, programs can declare
IPPL&nbsp; <tt>Array&lt;&gt;</tt>s with elements other than basic
arithmetic types like <tt>int</tt> or <tt>double</tt>.  In particular,
Vector&lt;&gt;, Tensor&lt;&gt;, and complex&lt;&gt; are explicitly
supported.  Please contact <a
href="mailto:pooma@acl.lanl.gov">pooma@acl.lanl.gov</a> for
information on using other, more complicated types.

<p>The <tt>Array&lt;&gt;::comp()</tt> method used on line&nbsp;16 does
<em>component forwarding</em>.  The expression <tt>rays.comp(2)</tt>
returns an <tt>Array&lt;double&gt;</tt> that supports writing into the
third component of each vector element of rays. This is a
data-parallel statement that works in a way analogous to the loop at
lines 22-25, except that the IPPL&nbsp; evaluator will calculate
patches in parallel. Thus, if a program had an array of tensors
<tt>T</tt>, it could change the element in the 1st row, 2nd column
with <tt>T.comp(0, 1)</tt>.  Note that, unlike <tt>Array&lt;&gt;</tt>,
both <tt>Vector&lt;&gt;</tt> and <tt>Tensor&lt;&gt;</tt> always index
from zero.

<p>Line&nbsp;24 shows that, as expected, the i<sup>th</sup> component
of a <tt>Vector&lt;&gt;</tt> <tt>V</tt> can be accessed for both
reading and writing using the syntax <tt>V(i)</tt>;
<tt>Tensor&lt;&gt;</tt> element access requires two subscripts.  Thus,
the first subscript in the expression <tt>rays(i)(0)</tt> returns the
i<sup>th</sup> element of the <tt>Vector&lt;&gt;</tt> <tt>rays</tt>,
while the second subscript returns the first component of that vector.

<p>Line&nbsp;28 shows that <tt>Vector&lt;&gt;</tt>s can be initialized
with one to three element values. Similarly, instances of
<tt>Tensor&lt;&gt;</tt> can be initialized with up to nine element
values.

<p>The data-parallel expression on line&nbsp;31 shows that the usual
math functions can be applied to entire arrays. The unary and binary
functions supported are:

<center><table>
<tr>	<td width=50 valign=bottom><tt>acos</tt></td>
	<td width=50 valign=bottom><tt>asin</tt></td>
	<td width=50 valign=bottom><tt>atan</tt></td>
	<td width=50 valign=bottom><tt>ceil</tt></td>
	<td width=50 valign=bottom><tt>cos</tt></td>
	<td width=50 valign=bottom><tt>cosh</tt></td>
	</tr>
<tr>	<td width=50 valign=bottom><tt>exp</tt></td>
	<td width=50 valign=bottom><tt>fabs</tt></td>
	<td width=50 valign=bottom><tt>floor</tt></td>
	<td width=50 valign=bottom><tt>log</tt></td>
	<td width=50 valign=bottom><tt>log10</tt></td>
	<td width=50 valign=bottom><tt>sin</tt></td>
	</tr>
<tr>	<td width=50 valign=bottom><tt>sinh</tt></td>
	<td width=50 valign=bottom><tt>sqrt</tt></td>
	<td width=50 valign=bottom><tt>tan</tt></td>
	<td width=50 valign=bottom><tt>tanh</tt></td>
	<td width=50 valign=bottom><tt>imag</tt></td>
	<td width=50 valign=bottom><tt>real</tt></td>
	</tr>
<tr>	<td width=50 valign=bottom><tt>abs</tt></td>
	<td width=50 valign=bottom><tt>arg</tt></td>
	<td width=50 valign=bottom><tt>norm</tt><sup>1</sup></td>
	<td width=50 valign=bottom></td>
	<td width=50 valign=bottom></td>
	<td width=50 valign=bottom></td>
	</tr>
<tr>	<td width=50 valign=bottom><tt>ldexp</tt></td>
	<td width=50 valign=bottom><tt>pow</tt></td>
	<td width=50 valign=bottom><tt>fmod</tt></td>
	<td width=50 valign=bottom><tt>atan2</tt></td>
	<td width=50 valign=bottom><tt>dot</tt><sup>2</sup></td>
	<td width=50 valign=bottom><tt>polar</tt><sup>3</sup>
	</tr>
<tr>	<td colspan=6 align=left>1. complex&lt;T&gt; only</td></tr>
<tr>	<td colspan=6 align=left>2. Vector and Tensors only</td></tr>
<tr>	<td colspan=6 align=left>3. complex&lt;T&gt; only</td></tr>
</table></center>

<p>Line&nbsp;34 is a data-parallel expression on vectors. In addition
to dot product, the normal arithmetic functions involving
<tt>Vector&lt;&gt;</tt> and <tt>Tensor&lt;&gt;</tt> are
supported. This release of IPPL&nbsp; does not offer double-dot
products, cross products or any other vector or tensor operations;
these are being considered for future releases.

<p>Finally, as line&nbsp;37 shows, arrays of vectors can be output
like arrays of any other type.

</body>
</html>
